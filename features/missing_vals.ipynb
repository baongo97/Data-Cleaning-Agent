{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691226d2",
   "metadata": {},
   "source": [
    "## **Feature:** Missing Vals\n",
    "\n",
    "**Names:** Tanat\n",
    "\n",
    "### **What it does**\n",
    "Intelligently handles missing values in datasets using data cleaning best practices. The feature analyzes your data's characteristics (data types, distribution, missing percentages) and automatically suggests or applies the most appropriate imputation method.\n",
    "\n",
    "Users can either get imputation recommendations or have the system automatically clean their data based on best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff1f7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Get API Key\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "\n",
    "# Import libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Langchain imports\n",
    "from langchain_openai import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866b0e98",
   "metadata": {},
   "source": [
    "### **Helper Functions**\n",
    "\n",
    "- `analyze_missing_values(df, drop_threshold=0.5)` = Suggest missing vlaue imputation strategies based on best practices/heuristics\n",
    "- `auto_impute(df, drop_threshold=0.5)` = Automatically imputes missing values in a DataFrame based on simple best-practice heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60424d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df, drop_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Suggest missing value imputation strategies based on heuristics.\n",
    "    \"\"\"\n",
    "    suggestions = {}\n",
    "    for col in df.columns:\n",
    "        missing_pct = df[col].isna().mean()\n",
    "        dtype = df[col].dtype\n",
    "        suggestion = None\n",
    "\n",
    "        if missing_pct == 0:\n",
    "            continue\n",
    "        if missing_pct > drop_threshold:\n",
    "            suggestion = \"Drop column (too many missing values)\"\n",
    "        else:\n",
    "            # Numerical features\n",
    "            if pd.api.types.is_numeric_dtype(dtype):\n",
    "                n_unique = df[col].nunique(dropna=True)\n",
    "                if n_unique < 15:  # numeric but categorical (like codes)\n",
    "                    suggestion = \"Mode imputation (numeric categorical)\"\n",
    "                else:\n",
    "                    non_null = df[col].dropna()\n",
    "                    if len(non_null) < 10:\n",
    "                        suggestion = \"Median imputation (small sample)\"\n",
    "                    else:\n",
    "                        skewness = non_null.skew()\n",
    "                        suggestion = \"Mean imputation\" if abs(skewness) < 1 else \"Median imputation (skewed)\"\n",
    "            \n",
    "            # Categorical features\n",
    "            elif pd.api.types.is_categorical_dtype(dtype) or pd.api.types.is_object_dtype(dtype):\n",
    "                n_unique = df[col].nunique(dropna=True)\n",
    "                if n_unique <= 10:\n",
    "                    suggestion = \"Mode imputation (most frequent)\"\n",
    "                else:\n",
    "                    suggestion = \"Impute with 'Unknown' or predictive model\"\n",
    "\n",
    "            # Boolean features\n",
    "            elif pd.api.types.is_bool_dtype(dtype):\n",
    "                suggestion = \"Mode imputation (True/False)\"\n",
    "\n",
    "            # Datetime features\n",
    "            elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "                suggestion = \"Forward/Backward fill or interpolation (time series)\"\n",
    "            \n",
    "            else:\n",
    "                suggestion = \"Custom handling needed\"\n",
    "\n",
    "        suggestions[col] = {\n",
    "            \"dtype\": str(dtype),\n",
    "            \"missing_pct\": round(missing_pct, 3),\n",
    "            \"suggestion\": suggestion\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame.from_dict(suggestions, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "100e6386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_impute(df, drop_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Automatically imputes missing values in a DataFrame based on simple \n",
    "    best-practice heuristics.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        missing_pct = df[col].isna().mean()\n",
    "        dtype = df[col].dtype\n",
    "\n",
    "        # Drop if too many missing\n",
    "        if missing_pct > drop_threshold:\n",
    "            df = df.drop(columns=[col])\n",
    "            continue\n",
    "\n",
    "        # Numerical features (mean or median)\n",
    "        if np.issubdtype(dtype, np.number):\n",
    "            skewness = df[col].dropna().skew()\n",
    "            if abs(skewness) < 1:\n",
    "                fill_value = df[col].mean()\n",
    "                print(f\"Imputed '{col}' with mean\")\n",
    "            else:\n",
    "                fill_value = df[col].median()\n",
    "                print(f\"'{col}' is skewed, imputed with median\")\n",
    "            df[col] = df[col].fillna(fill_value)\n",
    "\n",
    "        # Categorical features\n",
    "        elif df[col].dtype == \"object\" or pd.api.types.is_categorical_dtype(df[col]):\n",
    "            n_unique = df[col].nunique(dropna=True)\n",
    "            unique_ratio = n_unique / df.shape[0]\n",
    "            # Low Cardinality Fill with median else impute with unknown \n",
    "            if n_unique <= 20 or unique_ratio < 0.05:\n",
    "                fill_value = df[col].mode(dropna=True)[0] if not df[col].mode(dropna=True).empty else \"Unknown\"\n",
    "                df[col] = df[col].fillna(fill_value)\n",
    "                print(f\"{col} has low Cardinality, imputed with mode\")\n",
    "            else:\n",
    "                df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "        # Datetime features\n",
    "        elif np.issubdtype(dtype, np.datetime64):\n",
    "            df[col] = df[col].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "\n",
    "        # Fallback\n",
    "        else:\n",
    "            df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e2b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_col(series, strategy):\n",
    "    \"\"\"\n",
    "    Impute missing values in a pandas Series using the specified strategy.\n",
    "    Supported strategies: 'mean', 'median', 'mode', 'unknown', 'ffill', 'bfill'\n",
    "    \"\"\"\n",
    "    if strategy == \"mean\":\n",
    "        fill_value = series.mean()\n",
    "        return series.fillna(fill_value)\n",
    "    elif strategy == \"median\":\n",
    "        fill_value = series.median()\n",
    "        return series.fillna(fill_value)\n",
    "    elif strategy == \"mode\":\n",
    "        fill_value = series.mode(dropna=True)[0] if not series.mode(dropna=True).empty else \"Unknown\"\n",
    "        return series.fillna(fill_value)\n",
    "    elif strategy == \"unknown\":\n",
    "        return series.fillna(\"Unknown\")\n",
    "    elif strategy == \"ffill\":\n",
    "        return series.fillna(method=\"ffill\")\n",
    "    elif strategy == \"bfill\":\n",
    "        return series.fillna(method=\"bfill\")\n",
    "    else:\n",
    "        print(f\"Unknown strategy '{strategy}', no imputation performed.\")\n",
    "        return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b21dd952",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_docs = \"\"\" Helper functions available: \n",
    "- auto_impute(df, drop_threshold=0.5): Automatically imputes missing values in a DataFrame based on simple best-practice heuristics. Returns modified DataFrame.\n",
    "- impute_col(series, strategy): Impute missing values in a pandas Series using the specified strategy. Returns modified series.\n",
    "    - Supported Strategies: 'mean', 'median', 'mode', 'unknown', 'ffill', 'bfill'\n",
    "- analyze_missing_values(df, drop_threshold=0.5): Analyze missing values and provide imputation suggestions. Returns DataFrame with analysis.\n",
    "\n",
    "Examples:\n",
    "- df = auto_impute(df)  # automatic imputation\n",
    "- df['column_name'] = impute_col(df['column_name'], 'mean')  # For specific column imputation\n",
    "- analysis = analyze_missing_values(df)  # For analysis only\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34049fe8",
   "metadata": {},
   "source": [
    "# **MAIN FEATURE FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54132b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_vals(df, user_query):\n",
    "    \"\"\"\n",
    "    Main function that gets called by the main router.\n",
    "    MUST take (df, user_query) and return df\n",
    "    \"\"\"\n",
    "    \n",
    "    suggestions = analyze_missing_values(df)\n",
    "    \n",
    "    # Get columns with missing values for the LLM\n",
    "    columns_with_missing = df.columns[df.isnull().any()].tolist()\n",
    "    missing_info = {col: {'missing_count': df[col].isnull().sum(), 'missing_pct': df[col].isnull().mean()} \n",
    "                   for col in columns_with_missing}\n",
    "\n",
    "    # Create message chain\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=helper_docs))\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent trying to handle missing values.\n",
    "    \n",
    "    Dataset info: Shape: {df.shape}, Sample: {df.head(3).to_string()}\n",
    "    \n",
    "    Columns with missing values: {len(columns_with_missing)} columns\n",
    "    Missing value summary: {missing_info}\n",
    "    \n",
    "    imputation suggestions: {suggestions if not suggestions.empty else \"No Missing Values!\"}\n",
    "\n",
    "    Libraries available:\n",
    "    - pd (pandas), np (numpy)\n",
    "    - math, re, datetime\n",
    "    - preprocessing, impute (from sklearn)\n",
    "    \n",
    "    Rules:\n",
    "    - Return only executable Python code, no explanations, no markdown blocks\n",
    "    - Use helper functions if needed\n",
    "    - ASSUME \"df\" IS ALREADY DEFINED\n",
    "    - ALWAYS assign the result back to df when modifying: df = auto_impute(df)\n",
    "    - RECOMMENDED: Use auto_impute(df) for automatic imputation as it handles all column names correctly\n",
    "    - Only use impute_col for specific single-column imputation requests\n",
    "    - In order to generate a response/message to the user use print statements\n",
    "    print(\"message\")\n",
    "    - Write a detailed print message to summarise actions taken and reasons\n",
    "    \n",
    "    Common query patterns:\n",
    "    - \"automatic imputation\": df = auto_impute(df)\n",
    "    - \"analysis only\": analysis = analyze_missing_values(df); print(analysis)\n",
    "    - \"impute missing values using suggested strategy\": df['column_name'] = impute_col(df['column_name'], 'mean')\n",
    "    \"\"\"))\n",
    "    messages.append(HumanMessage(content=f\"User request: {user_query}\"))\n",
    "    \n",
    "    # Call LLM with message chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "    \n",
    "    # Execute code\n",
    "    try:\n",
    "        original_df = df.copy()\n",
    "        # Create local namespace with our variables\n",
    "        local_vars = {\n",
    "            'df': df.copy(),\n",
    "            'original_df': original_df,\n",
    "            'suggestions': suggestions,\n",
    "            'columns_with_missing': columns_with_missing,\n",
    "            'missing_info': missing_info,\n",
    "            'pd': pd,\n",
    "            'np': np,\n",
    "            'auto_impute': auto_impute,\n",
    "            'impute_col': impute_col,\n",
    "            'analyze_missing_values': analyze_missing_values,\n",
    "            'print': print\n",
    "        }\n",
    "        \n",
    "        exec(generated_code, globals(), local_vars)\n",
    "        return local_vars['df']\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Generated Code:{generated_code}\")\n",
    "        return original_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b14a9",
   "metadata": {},
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1082194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enter CSV filename from \"datasets\" folder\n",
    "# dataset_name = \"Life Expectancy Data.csv\"\n",
    "\n",
    "# # Build CSV path (to avoid import errors)\n",
    "# load_dotenv()\n",
    "# PROJECT_ROOT = Path(os.environ[\"PROJECT_ROOT\"])\n",
    "# path = PROJECT_ROOT / \"datasets\" / dataset_name\n",
    "\n",
    "# df = pd.read_csv(path)\n",
    "# test_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "409eda29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values have been imputed using the suggested strategies: mean for 'Life expectancy', 'Alcohol', ' BMI ', 'Total expenditure', and 'Schooling'; median for 'Adult Mortality', 'Hepatitis B', 'Polio', 'Diphtheria', 'GDP', 'Population', ' thinness  1-19 years', ' thinness 5-9 years', and 'Income composition of resources'.\n"
     ]
    }
   ],
   "source": [
    "# query = \"impute missing values using suggested strategy\"\n",
    "# result = missing_vals(test_df, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761b0448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2938 entries, 0 to 2937\n",
      "Data columns (total 22 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Country                          2938 non-null   object \n",
      " 1   Year                             2938 non-null   int64  \n",
      " 2   Status                           2938 non-null   object \n",
      " 3   Life expectancy                  2938 non-null   float64\n",
      " 4   Adult Mortality                  2938 non-null   float64\n",
      " 5   infant deaths                    2938 non-null   int64  \n",
      " 6   Alcohol                          2938 non-null   float64\n",
      " 7   percentage expenditure           2938 non-null   float64\n",
      " 8   Hepatitis B                      2938 non-null   float64\n",
      " 9   Measles                          2938 non-null   int64  \n",
      " 10   BMI                             2938 non-null   float64\n",
      " 11  under-five deaths                2938 non-null   int64  \n",
      " 12  Polio                            2938 non-null   float64\n",
      " 13  Total expenditure                2938 non-null   float64\n",
      " 14  Diphtheria                       2938 non-null   float64\n",
      " 15   HIV/AIDS                        2938 non-null   float64\n",
      " 16  GDP                              2938 non-null   float64\n",
      " 17  Population                       2938 non-null   float64\n",
      " 18   thinness  1-19 years            2938 non-null   float64\n",
      " 19   thinness 5-9 years              2938 non-null   float64\n",
      " 20  Income composition of resources  2938 non-null   float64\n",
      " 21  Schooling                        2938 non-null   float64\n",
      "dtypes: float64(16), int64(4), object(2)\n",
      "memory usage: 505.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# result.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
