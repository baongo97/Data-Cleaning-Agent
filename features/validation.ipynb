{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691226d2",
   "metadata": {},
   "source": [
    "## **Feature:** Data Validation\n",
    "\n",
    "**Names:** Gia Bao Ngo\n",
    "### **What it does**\n",
    "Provides comprehensive data validation capabilities including email format validation, phone number validation, numeric range validation, cross-column consistency checks, categorical value validation, and generates detailed validation reports with data quality scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff1f7555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Get API Key\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API Key not found\")\n",
    "\n",
    "# Import libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Additional imports for validation\n",
    "import math\n",
    "import re\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Langchain imports\n",
    "from langchain_openai import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a88657",
   "metadata": {},
   "source": [
    "### **Helper Functions**\n",
    "- `validate_email_format(series)` - Check email format validity using regex patterns\n",
    "- `validate_phone_format(series, country_code=None)` - Phone number validation with international support\n",
    "- `validate_numeric_ranges(df, column, min_val=None, max_val=None)` - Range validation with boundary checks\n",
    "- `check_data_consistency(df)` - Cross-column consistency checks\n",
    "- `validate_categorical_values(df, column, allowed_values)` - Check against allowed value lists\n",
    "- `generate_validation_report(df, rules_dict)` - Comprehensive validation report with quality scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60424d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_email_format(series):\n",
    "    \"\"\"\n",
    "    Check email format validity using regex patterns.\n",
    "    \n",
    "    Parameters:\n",
    "    - series: pandas Series containing email addresses\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with validation results and statistics\n",
    "    \"\"\"\n",
    "    # Comprehensive email regex pattern\n",
    "    email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "    \n",
    "    # Remove null values for validation\n",
    "    non_null_series = series.dropna()\n",
    "    total_count = len(series)\n",
    "    non_null_count = len(non_null_series)\n",
    "    null_count = total_count - non_null_count\n",
    "    \n",
    "    if non_null_count == 0:\n",
    "        return {\n",
    "            'valid_emails': 0,\n",
    "            'invalid_emails': 0,\n",
    "            'null_count': null_count,\n",
    "            'total_count': total_count,\n",
    "            'validity_rate': 0.0,\n",
    "            'invalid_samples': [],\n",
    "            'common_issues': []\n",
    "        }\n",
    "    \n",
    "    # Convert to string and validate\n",
    "    email_strings = non_null_series.astype(str).str.strip().str.lower()\n",
    "    valid_mask = email_strings.str.match(email_pattern, na=False)\n",
    "    \n",
    "    valid_count = valid_mask.sum()\n",
    "    invalid_count = non_null_count - valid_count\n",
    "    validity_rate = (valid_count / non_null_count) * 100\n",
    "    \n",
    "    # Get invalid email samples\n",
    "    invalid_emails = email_strings[~valid_mask].head(10).tolist()\n",
    "    \n",
    "    # Analyze common issues\n",
    "    common_issues = []\n",
    "    if invalid_count > 0:\n",
    "        invalid_series = email_strings[~valid_mask]\n",
    "        \n",
    "        # Check for missing @ symbol\n",
    "        missing_at = invalid_series.str.contains('@', na=False).sum()\n",
    "        if missing_at < len(invalid_series):\n",
    "            common_issues.append(f\"Missing @ symbol: {len(invalid_series) - missing_at} cases\")\n",
    "        \n",
    "        # Check for missing domain\n",
    "        has_at = invalid_series.str.contains('@', na=False)\n",
    "        if has_at.any():\n",
    "            at_emails = invalid_series[has_at]\n",
    "            missing_domain = at_emails.str.split('@').str[1].str.contains(r'\\.', na=False).sum()\n",
    "            if missing_domain < len(at_emails):\n",
    "                common_issues.append(f\"Missing domain extension: {len(at_emails) - missing_domain} cases\")\n",
    "        \n",
    "        # Check for whitespace issues\n",
    "        has_whitespace = invalid_series.str.contains(r'\\s', na=False).sum()\n",
    "        if has_whitespace > 0:\n",
    "            common_issues.append(f\"Contains whitespace: {has_whitespace} cases\")\n",
    "        \n",
    "        # Check for multiple @ symbols\n",
    "        multiple_at = invalid_series.str.count('@') > 1\n",
    "        if multiple_at.any():\n",
    "            common_issues.append(f\"Multiple @ symbols: {multiple_at.sum()} cases\")\n",
    "    \n",
    "    print(f\"=== EMAIL VALIDATION RESULTS ===\")\n",
    "    print(f\"Total records: {total_count}\")\n",
    "    print(f\"Non-null records: {non_null_count}\")\n",
    "    print(f\"Valid emails: {valid_count}\")\n",
    "    print(f\"Invalid emails: {invalid_count}\")\n",
    "    print(f\"Null emails: {null_count}\")\n",
    "    print(f\"Validity rate: {validity_rate:.1f}%\")\n",
    "    \n",
    "    if invalid_emails:\n",
    "        print(f\"\\nSample invalid emails:\")\n",
    "        for email in invalid_emails[:5]:\n",
    "            print(f\"  {email}\")\n",
    "    \n",
    "    if common_issues:\n",
    "        print(f\"\\nCommon issues found:\")\n",
    "        for issue in common_issues:\n",
    "            print(f\"  {issue}\")\n",
    "    \n",
    "    return {\n",
    "        'valid_emails': valid_count,\n",
    "        'invalid_emails': invalid_count,\n",
    "        'null_count': null_count,\n",
    "        'total_count': total_count,\n",
    "        'validity_rate': validity_rate,\n",
    "        'invalid_samples': invalid_emails,\n",
    "        'common_issues': common_issues\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a090e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_phone_format(series, country_code=None):\n",
    "    \"\"\"\n",
    "    Phone number validation with international support using regex patterns.\n",
    "    \n",
    "    Parameters:\n",
    "    - series: pandas Series containing phone numbers\n",
    "    - country_code: country code for validation (e.g., 'US', 'GB', None for international)\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with validation results and statistics\n",
    "    \"\"\"\n",
    "    # Remove null values for validation\n",
    "    non_null_series = series.dropna()\n",
    "    total_count = len(series)\n",
    "    non_null_count = len(non_null_series)\n",
    "    null_count = total_count - non_null_count\n",
    "    \n",
    "    if non_null_count == 0:\n",
    "        return {\n",
    "            'valid_phones': 0,\n",
    "            'invalid_phones': 0,\n",
    "            'null_count': null_count,\n",
    "            'total_count': total_count,\n",
    "            'validity_rate': 0.0,\n",
    "            'invalid_samples': [],\n",
    "            'common_issues': []\n",
    "        }\n",
    "    \n",
    "    # Convert to string and clean\n",
    "    phone_strings = non_null_series.astype(str).str.strip()\n",
    "    \n",
    "    # Define phone patterns\n",
    "    patterns = {\n",
    "        'US': [\n",
    "            r'^\\+1[2-9]\\d{2}[2-9]\\d{2}\\d{4}$',  # +1XXXXXXXXXX\n",
    "            r'^1[2-9]\\d{2}[2-9]\\d{2}\\d{4}$',    # 1XXXXXXXXXX\n",
    "            r'^[2-9]\\d{2}[2-9]\\d{2}\\d{4}$',     # XXXXXXXXXX\n",
    "            r'^\\([2-9]\\d{2}\\)\\s?[2-9]\\d{2}-\\d{4}$',  # (XXX) XXX-XXXX\n",
    "            r'^[2-9]\\d{2}-[2-9]\\d{2}-\\d{4}$',   # XXX-XXX-XXXX\n",
    "            r'^[2-9]\\d{2}\\.[2-9]\\d{2}\\.\\d{4}$'  # XXX.XXX.XXXX\n",
    "        ],\n",
    "        'international': [\n",
    "            r'^\\+\\d{1,3}\\d{4,14}$',  # +CCXXXXXXXXX (country code + number)\n",
    "            r'^\\d{7,15}$'            # Basic number validation\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Choose patterns based on country code\n",
    "    if country_code == 'US':\n",
    "        validation_patterns = patterns['US']\n",
    "    else:\n",
    "        validation_patterns = patterns['international']\n",
    "    \n",
    "    # Clean phone numbers for validation\n",
    "    cleaned_phones = phone_strings.str.replace(r'[\\s\\-\\(\\)\\.]', '', regex=True)\n",
    "    \n",
    "    valid_count = 0\n",
    "    invalid_phones = []\n",
    "    common_issues = []\n",
    "    \n",
    "    for phone in cleaned_phones:\n",
    "        is_valid = False\n",
    "        for pattern in validation_patterns:\n",
    "            # For pattern matching, use original format\n",
    "            original_phone = phone_strings[cleaned_phones == phone].iloc[0] if len(phone_strings[cleaned_phones == phone]) > 0 else phone\n",
    "            \n",
    "            if re.match(pattern, phone) or re.match(pattern, original_phone):\n",
    "                is_valid = True\n",
    "                break\n",
    "        \n",
    "        if is_valid:\n",
    "            valid_count += 1\n",
    "        else:\n",
    "            if len(invalid_phones) < 10:\n",
    "                invalid_phones.append(original_phone if 'original_phone' in locals() else phone)\n",
    "    \n",
    "    invalid_count = non_null_count - valid_count\n",
    "    validity_rate = (valid_count / non_null_count) * 100\n",
    "    \n",
    "    # Analyze common issues\n",
    "    if invalid_count > 0:\n",
    "        invalid_series = phone_strings[~phone_strings.isin([p for p in phone_strings if any(re.match(pat, p.replace(r'[\\s\\-\\(\\)\\.]', '')) or re.match(pat, p) for pat in validation_patterns)])]\n",
    "        \n",
    "        # Check for too short numbers\n",
    "        too_short = cleaned_phones.str.len() < 7\n",
    "        if too_short.any():\n",
    "            common_issues.append(f\"Too short (< 7 digits): {too_short.sum()} cases\")\n",
    "        \n",
    "        # Check for too long numbers\n",
    "        too_long = cleaned_phones.str.len() > 15\n",
    "        if too_long.any():\n",
    "            common_issues.append(f\"Too long (> 15 digits): {too_long.sum()} cases\")\n",
    "        \n",
    "        # Check for non-numeric characters\n",
    "        has_letters = phone_strings.str.contains(r'[a-zA-Z]', na=False)\n",
    "        if has_letters.any():\n",
    "            common_issues.append(f\"Contains letters: {has_letters.sum()} cases\")\n",
    "        \n",
    "        # Check for missing country code (international)\n",
    "        if country_code != 'US':\n",
    "            missing_plus = ~phone_strings.str.startswith('+')\n",
    "            if missing_plus.any():\n",
    "                common_issues.append(f\"Missing country code (+): {missing_plus.sum()} cases\")\n",
    "    \n",
    "    print(f\"=== PHONE VALIDATION RESULTS ===\")\n",
    "    print(f\"Country code: {country_code or 'International'}\")\n",
    "    print(f\"Total records: {total_count}\")\n",
    "    print(f\"Non-null records: {non_null_count}\")\n",
    "    print(f\"Valid phones: {valid_count}\")\n",
    "    print(f\"Invalid phones: {invalid_count}\")\n",
    "    print(f\"Null phones: {null_count}\")\n",
    "    print(f\"Validity rate: {validity_rate:.1f}%\")\n",
    "    \n",
    "    if invalid_phones:\n",
    "        print(f\"\\nSample invalid phones:\")\n",
    "        for phone in invalid_phones[:5]:\n",
    "            print(f\"  {phone}\")\n",
    "    \n",
    "    if common_issues:\n",
    "        print(f\"\\nCommon issues found:\")\n",
    "        for issue in common_issues:\n",
    "            print(f\"  {issue}\")\n",
    "    \n",
    "    return {\n",
    "        'valid_phones': valid_count,\n",
    "        'invalid_phones': invalid_count,\n",
    "        'null_count': null_count,\n",
    "        'total_count': total_count,\n",
    "        'validity_rate': validity_rate,\n",
    "        'invalid_samples': invalid_phones,\n",
    "        'common_issues': common_issues\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dhae34rrfmb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_numeric_ranges(df, column, min_val=None, max_val=None):\n",
    "    \"\"\"\n",
    "    Range validation with boundary checks for numeric columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - column: column name to validate\n",
    "    - min_val: minimum allowed value (None = no minimum)\n",
    "    - max_val: maximum allowed value (None = no maximum)\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with validation results\n",
    "    \"\"\"\n",
    "    if column not in df.columns:\n",
    "        print(f\"Error: Column '{column}' not found in DataFrame\")\n",
    "        return None\n",
    "    \n",
    "    series = df[column]\n",
    "    \n",
    "    # Check if column is numeric\n",
    "    if not pd.api.types.is_numeric_dtype(series):\n",
    "        print(f\"Error: Column '{column}' is not numeric (dtype: {series.dtype})\")\n",
    "        return None\n",
    "    \n",
    "    total_count = len(series)\n",
    "    non_null_series = series.dropna()\n",
    "    non_null_count = len(non_null_series)\n",
    "    null_count = total_count - non_null_count\n",
    "    \n",
    "    if non_null_count == 0:\n",
    "        return {\n",
    "            'column': column,\n",
    "            'total_count': total_count,\n",
    "            'null_count': null_count,\n",
    "            'valid_count': 0,\n",
    "            'invalid_count': 0,\n",
    "            'validity_rate': 0.0,\n",
    "            'out_of_range_samples': []\n",
    "        }\n",
    "    \n",
    "    # Apply range validation\n",
    "    valid_mask = pd.Series([True] * non_null_count, index=non_null_series.index)\n",
    "    \n",
    "    below_min_count = 0\n",
    "    above_max_count = 0\n",
    "    out_of_range_samples = []\n",
    "    \n",
    "    if min_val is not None:\n",
    "        below_min_mask = non_null_series < min_val\n",
    "        below_min_count = below_min_mask.sum()\n",
    "        valid_mask &= ~below_min_mask\n",
    "        \n",
    "        # Get samples of values below minimum\n",
    "        below_min_values = non_null_series[below_min_mask].head(5).tolist()\n",
    "        out_of_range_samples.extend([f\"Below min ({min_val}): {val}\" for val in below_min_values])\n",
    "    \n",
    "    if max_val is not None:\n",
    "        above_max_mask = non_null_series > max_val\n",
    "        above_max_count = above_max_mask.sum()\n",
    "        valid_mask &= ~above_max_mask\n",
    "        \n",
    "        # Get samples of values above maximum\n",
    "        above_max_values = non_null_series[above_max_mask].head(5).tolist()\n",
    "        out_of_range_samples.extend([f\"Above max ({max_val}): {val}\" for val in above_max_values])\n",
    "    \n",
    "    valid_count = valid_mask.sum()\n",
    "    invalid_count = non_null_count - valid_count\n",
    "    validity_rate = (valid_count / non_null_count) * 100\n",
    "    \n",
    "    # Statistics\n",
    "    series_stats = {\n",
    "        'min': non_null_series.min(),\n",
    "        'max': non_null_series.max(),\n",
    "        'mean': non_null_series.mean(),\n",
    "        'std': non_null_series.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"=== NUMERIC RANGE VALIDATION: {column} ===\")\n",
    "    print(f\"Range constraints: {min_val if min_val is not None else 'No min'} to {max_val if max_val is not None else 'No max'}\")\n",
    "    print(f\"Total records: {total_count}\")\n",
    "    print(f\"Non-null records: {non_null_count}\")\n",
    "    print(f\"Valid values: {valid_count}\")\n",
    "    print(f\"Invalid values: {invalid_count}\")\n",
    "    print(f\"Null values: {null_count}\")\n",
    "    print(f\"Validity rate: {validity_rate:.1f}%\")\n",
    "    \n",
    "    if min_val is not None and below_min_count > 0:\n",
    "        print(f\"Values below minimum ({min_val}): {below_min_count}\")\n",
    "    if max_val is not None and above_max_count > 0:\n",
    "        print(f\"Values above maximum ({max_val}): {above_max_count}\")\n",
    "    \n",
    "    print(f\"\\nData statistics:\")\n",
    "    print(f\"  Actual range: {series_stats['min']:.2f} to {series_stats['max']:.2f}\")\n",
    "    print(f\"  Mean: {series_stats['mean']:.2f}\")\n",
    "    print(f\"  Std Dev: {series_stats['std']:.2f}\")\n",
    "    \n",
    "    if out_of_range_samples:\n",
    "        print(f\"\\nOut-of-range samples:\")\n",
    "        for sample in out_of_range_samples[:10]:\n",
    "            print(f\"  {sample}\")\n",
    "    \n",
    "    return {\n",
    "        'column': column,\n",
    "        'total_count': total_count,\n",
    "        'null_count': null_count,\n",
    "        'valid_count': valid_count,\n",
    "        'invalid_count': invalid_count,\n",
    "        'validity_rate': validity_rate,\n",
    "        'below_min_count': below_min_count,\n",
    "        'above_max_count': above_max_count,\n",
    "        'out_of_range_samples': out_of_range_samples,\n",
    "        'statistics': series_stats\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "t4buv0jv8w",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_consistency(df):\n",
    "    \"\"\"\n",
    "    Cross-column consistency checks to identify logical inconsistencies in data.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with consistency check results\n",
    "    \"\"\"\n",
    "    consistency_issues = []\n",
    "    total_checks = 0\n",
    "    failed_checks = 0\n",
    "    \n",
    "    print(f\"=== DATA CONSISTENCY CHECK ===\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    \n",
    "    # Check 1: Date consistency (if date columns exist)\n",
    "    date_columns = df.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "    if len(date_columns) >= 2:\n",
    "        for i in range(len(date_columns)):\n",
    "            for j in range(i+1, len(date_columns)):\n",
    "                col1, col2 = date_columns[i], date_columns[j]\n",
    "                \n",
    "                # Check if there are logical date relationships\n",
    "                if 'start' in col1.lower() and 'end' in col2.lower():\n",
    "                    total_checks += 1\n",
    "                    invalid_dates = df[df[col1] > df[col2]].dropna(subset=[col1, col2])\n",
    "                    if len(invalid_dates) > 0:\n",
    "                        failed_checks += 1\n",
    "                        consistency_issues.append({\n",
    "                            'type': 'date_logic',\n",
    "                            'description': f'{col1} after {col2}',\n",
    "                            'count': len(invalid_dates),\n",
    "                            'sample_indices': invalid_dates.index[:5].tolist()\n",
    "                        })\n",
    "                        print(f\"❌ Date logic issue: {len(invalid_dates)} records where {col1} > {col2}\")\n",
    "    \n",
    "    # Check 2: Numeric relationships\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Look for potential percentage columns that should sum to 100\n",
    "    potential_percentage_cols = [col for col in numeric_columns if 'percent' in col.lower() or '%' in col]\n",
    "    if len(potential_percentage_cols) >= 2:\n",
    "        total_checks += 1\n",
    "        # Check if rows sum to approximately 100\n",
    "        row_sums = df[potential_percentage_cols].sum(axis=1)\n",
    "        tolerance = 5  # 5% tolerance\n",
    "        invalid_sums = df[(row_sums < (100 - tolerance)) | (row_sums > (100 + tolerance))].dropna(subset=potential_percentage_cols)\n",
    "        \n",
    "        if len(invalid_sums) > 0:\n",
    "            failed_checks += 1\n",
    "            consistency_issues.append({\n",
    "                'type': 'percentage_sum',\n",
    "                'description': f'Percentage columns {potential_percentage_cols} do not sum to ~100%',\n",
    "                'count': len(invalid_sums),\n",
    "                'sample_indices': invalid_sums.index[:5].tolist()\n",
    "            })\n",
    "            print(f\"❌ Percentage sum issue: {len(invalid_sums)} records with percentage sums outside 95-105%\")\n",
    "    \n",
    "    # Check 3: Age consistency (if birth date and age columns exist)\n",
    "    age_cols = [col for col in df.columns if 'age' in col.lower()]\n",
    "    birth_cols = [col for col in date_columns if 'birth' in col.lower() or 'dob' in col.lower()]\n",
    "    \n",
    "    if age_cols and birth_cols and len(age_cols) > 0 and len(birth_cols) > 0:\n",
    "        for age_col in age_cols:\n",
    "            for birth_col in birth_cols:\n",
    "                if pd.api.types.is_numeric_dtype(df[age_col]):\n",
    "                    total_checks += 1\n",
    "                    # Calculate expected age from birth date\n",
    "                    current_date = datetime.datetime.now()\n",
    "                    expected_ages = (current_date - df[birth_col]).dt.days / 365.25\n",
    "                    age_diff = abs(df[age_col] - expected_ages)\n",
    "                    \n",
    "                    # Allow 1 year tolerance\n",
    "                    invalid_ages = df[age_diff > 1].dropna(subset=[age_col, birth_col])\n",
    "                    if len(invalid_ages) > 0:\n",
    "                        failed_checks += 1\n",
    "                        consistency_issues.append({\n",
    "                            'type': 'age_birth_mismatch',\n",
    "                            'description': f'{age_col} inconsistent with {birth_col}',\n",
    "                            'count': len(invalid_ages),\n",
    "                            'sample_indices': invalid_ages.index[:5].tolist()\n",
    "                        })\n",
    "                        print(f\"❌ Age-birth date mismatch: {len(invalid_ages)} records with >1 year difference\")\n",
    "    \n",
    "    # Check 4: Geographic consistency (if state/country columns exist)\n",
    "    geo_columns = [col for col in df.columns if any(geo_term in col.lower() for geo_term in ['state', 'country', 'city', 'zip', 'postal'])]\n",
    "    \n",
    "    # Check for impossible zip codes vs states (US example)\n",
    "    zip_cols = [col for col in geo_columns if 'zip' in col.lower() or 'postal' in col.lower()]\n",
    "    state_cols = [col for col in geo_columns if 'state' in col.lower()]\n",
    "    \n",
    "    if zip_cols and state_cols:\n",
    "        for zip_col in zip_cols:\n",
    "            for state_col in state_cols:\n",
    "                total_checks += 1\n",
    "                # Basic zip code format check for US\n",
    "                us_states = ['CA', 'NY', 'TX', 'FL', 'IL', 'PA', 'OH', 'GA', 'NC', 'MI']  # Sample states\n",
    "                state_zip_ranges = {\n",
    "                    'CA': [(90000, 96999)],\n",
    "                    'NY': [(10000, 14999)],\n",
    "                    'TX': [(73000, 79999), (75000, 79999)],\n",
    "                    'FL': [(32000, 34999)],\n",
    "                }\n",
    "                \n",
    "                # This is a simplified check - in practice you'd have a complete mapping\n",
    "                inconsistent_zip_state = 0\n",
    "                for state, zip_ranges in state_zip_ranges.items():\n",
    "                    state_data = df[df[state_col].str.upper() == state]\n",
    "                    if len(state_data) > 0:\n",
    "                        for zip_range in zip_ranges:\n",
    "                            zip_nums = pd.to_numeric(state_data[zip_col].astype(str).str[:5], errors='coerce')\n",
    "                            invalid_zips = state_data[~((zip_nums >= zip_range[0]) & (zip_nums <= zip_range[1]))].dropna(subset=[zip_col])\n",
    "                            inconsistent_zip_state += len(invalid_zips)\n",
    "                \n",
    "                if inconsistent_zip_state > 0:\n",
    "                    failed_checks += 1\n",
    "                    consistency_issues.append({\n",
    "                        'type': 'geographic_mismatch',\n",
    "                        'description': f'Zip codes inconsistent with states',\n",
    "                        'count': inconsistent_zip_state,\n",
    "                        'sample_indices': []\n",
    "                    })\n",
    "                    print(f\"❌ Geographic inconsistency: ~{inconsistent_zip_state} zip-state mismatches detected\")\n",
    "    \n",
    "    # Check 5: Duplicate ID checks\n",
    "    id_columns = [col for col in df.columns if any(id_term in col.lower() for id_term in ['id', 'key', 'uuid'])]\n",
    "    for id_col in id_columns:\n",
    "        if id_col.lower() in ['id', 'user_id', 'customer_id', 'primary_key']:\n",
    "            total_checks += 1\n",
    "            duplicates = df[df[id_col].duplicated()].dropna(subset=[id_col])\n",
    "            if len(duplicates) > 0:\n",
    "                failed_checks += 1\n",
    "                consistency_issues.append({\n",
    "                    'type': 'duplicate_ids',\n",
    "                    'description': f'Duplicate values in ID column {id_col}',\n",
    "                    'count': len(duplicates),\n",
    "                    'sample_indices': duplicates.index[:5].tolist()\n",
    "                })\n",
    "                print(f\"❌ Duplicate IDs: {len(duplicates)} duplicate values in {id_col}\")\n",
    "    \n",
    "    # Summary\n",
    "    consistency_rate = ((total_checks - failed_checks) / total_checks * 100) if total_checks > 0 else 100\n",
    "    \n",
    "    print(f\"\\n=== CONSISTENCY SUMMARY ===\")\n",
    "    print(f\"Total consistency checks performed: {total_checks}\")\n",
    "    print(f\"Checks passed: {total_checks - failed_checks}\")\n",
    "    print(f\"Checks failed: {failed_checks}\")\n",
    "    print(f\"Consistency rate: {consistency_rate:.1f}%\")\n",
    "    \n",
    "    if consistency_issues:\n",
    "        print(f\"\\nIssues found:\")\n",
    "        for issue in consistency_issues:\n",
    "            print(f\"  • {issue['description']}: {issue['count']} records\")\n",
    "    else:\n",
    "        print(\"✅ No consistency issues detected!\")\n",
    "    \n",
    "    return {\n",
    "        'total_checks': total_checks,\n",
    "        'passed_checks': total_checks - failed_checks,\n",
    "        'failed_checks': failed_checks,\n",
    "        'consistency_rate': consistency_rate,\n",
    "        'issues': consistency_issues\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5sd9vb413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_categorical_values(df, column, allowed_values):\n",
    "    \"\"\"\n",
    "    Check categorical values against a list of allowed values.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - column: column name to validate\n",
    "    - allowed_values: list/set of allowed categorical values\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with validation results\n",
    "    \"\"\"\n",
    "    if column not in df.columns:\n",
    "        print(f\"Error: Column '{column}' not found in DataFrame\")\n",
    "        return None\n",
    "    \n",
    "    series = df[column]\n",
    "    total_count = len(series)\n",
    "    non_null_series = series.dropna()\n",
    "    non_null_count = len(non_null_series)\n",
    "    null_count = total_count - non_null_count\n",
    "    \n",
    "    if non_null_count == 0:\n",
    "        return {\n",
    "            'column': column,\n",
    "            'total_count': total_count,\n",
    "            'null_count': null_count,\n",
    "            'valid_count': 0,\n",
    "            'invalid_count': 0,\n",
    "            'validity_rate': 0.0,\n",
    "            'invalid_values': [],\n",
    "            'allowed_values': list(allowed_values)\n",
    "        }\n",
    "    \n",
    "    # Convert allowed values to set for faster lookup\n",
    "    allowed_set = set(allowed_values)\n",
    "    \n",
    "    # Convert series values to string for comparison\n",
    "    series_values = non_null_series.astype(str)\n",
    "    \n",
    "    # Find valid and invalid values\n",
    "    valid_mask = series_values.isin([str(val) for val in allowed_set])\n",
    "    valid_count = valid_mask.sum()\n",
    "    invalid_count = non_null_count - valid_count\n",
    "    validity_rate = (valid_count / non_null_count) * 100\n",
    "    \n",
    "    # Get unique invalid values\n",
    "    invalid_values = series_values[~valid_mask].unique().tolist()\n",
    "    invalid_counts = series_values[~valid_mask].value_counts().head(10).to_dict()\n",
    "    \n",
    "    # Get unique values in the column\n",
    "    unique_values = series_values.unique()\n",
    "    unique_count = len(unique_values)\n",
    "    \n",
    "    # Suggest potential matches for invalid values (fuzzy matching)\n",
    "    suggestions = {}\n",
    "    if invalid_values:\n",
    "        from difflib import get_close_matches\n",
    "        for invalid_val in invalid_values[:5]:  # Only check top 5 invalid values\n",
    "            matches = get_close_matches(str(invalid_val), [str(v) for v in allowed_values], n=3, cutoff=0.6)\n",
    "            if matches:\n",
    "                suggestions[invalid_val] = matches\n",
    "    \n",
    "    print(f\"=== CATEGORICAL VALIDATION: {column} ===\")\n",
    "    print(f\"Total records: {total_count}\")\n",
    "    print(f\"Non-null records: {non_null_count}\")\n",
    "    print(f\"Valid values: {valid_count}\")\n",
    "    print(f\"Invalid values: {invalid_count}\")\n",
    "    print(f\"Null values: {null_count}\")\n",
    "    print(f\"Validity rate: {validity_rate:.1f}%\")\n",
    "    print(f\"Unique values found: {unique_count}\")\n",
    "    print(f\"Allowed values: {len(allowed_values)}\")\n",
    "    \n",
    "    if invalid_values:\n",
    "        print(f\"\\nInvalid values found:\")\n",
    "        for invalid_val, count in list(invalid_counts.items())[:10]:\n",
    "            print(f\"  '{invalid_val}': {count} occurrences\")\n",
    "        \n",
    "        if suggestions:\n",
    "            print(f\"\\nPossible corrections:\")\n",
    "            for invalid_val, matches in suggestions.items():\n",
    "                print(f\"  '{invalid_val}' → {matches}\")\n",
    "    \n",
    "    # Show allowed values if reasonable number\n",
    "    if len(allowed_values) <= 20:\n",
    "        print(f\"\\nAllowed values: {sorted(list(allowed_set))}\")\n",
    "    else:\n",
    "        print(f\"\\nAllowed values (sample): {sorted(list(allowed_set))[:10]}... and {len(allowed_values)-10} more\")\n",
    "    \n",
    "    return {\n",
    "        'column': column,\n",
    "        'total_count': total_count,\n",
    "        'null_count': null_count,\n",
    "        'valid_count': valid_count,\n",
    "        'invalid_count': invalid_count,\n",
    "        'validity_rate': validity_rate,\n",
    "        'invalid_values': invalid_values,\n",
    "        'invalid_counts': invalid_counts,\n",
    "        'unique_count': unique_count,\n",
    "        'allowed_values': list(allowed_values),\n",
    "        'suggestions': suggestions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ibo2gfuwoyq",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_validation_report(df, rules_dict):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive validation report based on provided rules.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - rules_dict: dictionary with validation rules\n",
    "        Example: {\n",
    "            'email_columns': ['email', 'contact_email'],\n",
    "            'phone_columns': ['phone', 'mobile'],\n",
    "            'range_rules': {'age': {'min': 0, 'max': 150}, 'salary': {'min': 0}},\n",
    "            'categorical_rules': {'status': ['active', 'inactive'], 'category': ['A', 'B', 'C']},\n",
    "            'required_columns': ['id', 'name', 'email']\n",
    "        }\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with comprehensive validation report\n",
    "    \"\"\"\n",
    "    print(f\"=== COMPREHENSIVE VALIDATION REPORT ===\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Validation started at: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    validation_results = {\n",
    "        'metadata': {\n",
    "            'shape': df.shape,\n",
    "            'total_records': len(df),\n",
    "            'total_columns': len(df.columns),\n",
    "            'validation_timestamp': datetime.datetime.now().isoformat()\n",
    "        },\n",
    "        'column_validations': {},\n",
    "        'consistency_check': {},\n",
    "        'data_quality_score': 0.0,\n",
    "        'summary': {\n",
    "            'total_issues': 0,\n",
    "            'critical_issues': 0,\n",
    "            'warnings': 0,\n",
    "            'recommendations': []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    total_validation_points = 0\n",
    "    passed_validation_points = 0\n",
    "    \n",
    "    # 1. Required columns check\n",
    "    if 'required_columns' in rules_dict:\n",
    "        print(f\"\\n--- Required Columns Check ---\")\n",
    "        required_cols = rules_dict['required_columns']\n",
    "        missing_required = [col for col in required_cols if col not in df.columns]\n",
    "        \n",
    "        if missing_required:\n",
    "            print(f\"❌ Missing required columns: {missing_required}\")\n",
    "            validation_results['summary']['critical_issues'] += len(missing_required)\n",
    "        else:\n",
    "            print(f\"✅ All required columns present\")\n",
    "        \n",
    "        validation_results['required_columns'] = {\n",
    "            'required': required_cols,\n",
    "            'missing': missing_required,\n",
    "            'status': 'pass' if not missing_required else 'fail'\n",
    "        }\n",
    "    \n",
    "    # 2. Email validation\n",
    "    if 'email_columns' in rules_dict:\n",
    "        print(f\"\\n--- Email Validation ---\")\n",
    "        for email_col in rules_dict['email_columns']:\n",
    "            if email_col in df.columns:\n",
    "                email_results = validate_email_format(df[email_col])\n",
    "                validation_results['column_validations'][email_col] = {\n",
    "                    'type': 'email',\n",
    "                    'results': email_results\n",
    "                }\n",
    "                total_validation_points += email_results['total_count']\n",
    "                passed_validation_points += email_results['valid_emails']\n",
    "                \n",
    "                if email_results['validity_rate'] < 90:\n",
    "                    validation_results['summary']['warnings'] += 1\n",
    "                if email_results['validity_rate'] < 70:\n",
    "                    validation_results['summary']['critical_issues'] += 1\n",
    "    \n",
    "    # 3. Phone validation\n",
    "    if 'phone_columns' in rules_dict:\n",
    "        print(f\"\\n--- Phone Validation ---\")\n",
    "        country_code = rules_dict.get('phone_country_code', None)\n",
    "        for phone_col in rules_dict['phone_columns']:\n",
    "            if phone_col in df.columns:\n",
    "                phone_results = validate_phone_format(df[phone_col], country_code)\n",
    "                validation_results['column_validations'][phone_col] = {\n",
    "                    'type': 'phone',\n",
    "                    'results': phone_results\n",
    "                }\n",
    "                total_validation_points += phone_results['total_count']\n",
    "                passed_validation_points += phone_results['valid_phones']\n",
    "                \n",
    "                if phone_results['validity_rate'] < 90:\n",
    "                    validation_results['summary']['warnings'] += 1\n",
    "                if phone_results['validity_rate'] < 70:\n",
    "                    validation_results['summary']['critical_issues'] += 1\n",
    "    \n",
    "    # 4. Numeric range validation\n",
    "    if 'range_rules' in rules_dict:\n",
    "        print(f\"\\n--- Numeric Range Validation ---\")\n",
    "        for col, range_rule in rules_dict['range_rules'].items():\n",
    "            if col in df.columns:\n",
    "                min_val = range_rule.get('min')\n",
    "                max_val = range_rule.get('max')\n",
    "                range_results = validate_numeric_ranges(df, col, min_val, max_val)\n",
    "                \n",
    "                if range_results:\n",
    "                    validation_results['column_validations'][col] = {\n",
    "                        'type': 'numeric_range',\n",
    "                        'results': range_results\n",
    "                    }\n",
    "                    total_validation_points += range_results['total_count']\n",
    "                    passed_validation_points += range_results['valid_count']\n",
    "                    \n",
    "                    if range_results['validity_rate'] < 95:\n",
    "                        validation_results['summary']['warnings'] += 1\n",
    "                    if range_results['validity_rate'] < 85:\n",
    "                        validation_results['summary']['critical_issues'] += 1\n",
    "    \n",
    "    # 5. Categorical validation\n",
    "    if 'categorical_rules' in rules_dict:\n",
    "        print(f\"\\n--- Categorical Validation ---\")\n",
    "        for col, allowed_values in rules_dict['categorical_rules'].items():\n",
    "            if col in df.columns:\n",
    "                cat_results = validate_categorical_values(df, col, allowed_values)\n",
    "                \n",
    "                if cat_results:\n",
    "                    validation_results['column_validations'][col] = {\n",
    "                        'type': 'categorical',\n",
    "                        'results': cat_results\n",
    "                    }\n",
    "                    total_validation_points += cat_results['total_count']\n",
    "                    passed_validation_points += cat_results['valid_count']\n",
    "                    \n",
    "                    if cat_results['validity_rate'] < 95:\n",
    "                        validation_results['summary']['warnings'] += 1\n",
    "                    if cat_results['validity_rate'] < 80:\n",
    "                        validation_results['summary']['critical_issues'] += 1\n",
    "    \n",
    "    # 6. Data consistency check\n",
    "    print(f\"\\n--- Data Consistency Check ---\")\n",
    "    consistency_results = check_data_consistency(df)\n",
    "    validation_results['consistency_check'] = consistency_results\n",
    "    \n",
    "    if consistency_results['failed_checks'] > 0:\n",
    "        validation_results['summary']['warnings'] += consistency_results['failed_checks']\n",
    "    \n",
    "    # 7. Calculate overall data quality score\n",
    "    if total_validation_points > 0:\n",
    "        validation_results['data_quality_score'] = (passed_validation_points / total_validation_points) * 100\n",
    "    else:\n",
    "        validation_results['data_quality_score'] = 100.0\n",
    "    \n",
    "    # 8. Generate recommendations\n",
    "    recommendations = []\n",
    "    \n",
    "    if validation_results['data_quality_score'] < 80:\n",
    "        recommendations.append(\"Data quality score is below 80%. Consider comprehensive data cleaning.\")\n",
    "    \n",
    "    if validation_results['summary']['critical_issues'] > 0:\n",
    "        recommendations.append(f\"Address {validation_results['summary']['critical_issues']} critical data quality issues.\")\n",
    "    \n",
    "    if validation_results['summary']['warnings'] > 5:\n",
    "        recommendations.append(\"Multiple validation warnings detected. Review data entry processes.\")\n",
    "    \n",
    "    validation_results['summary']['recommendations'] = recommendations\n",
    "    validation_results['summary']['total_issues'] = validation_results['summary']['critical_issues'] + validation_results['summary']['warnings']\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\n=== VALIDATION SUMMARY ===\")\n",
    "    print(f\"Data Quality Score: {validation_results['data_quality_score']:.1f}%\")\n",
    "    print(f\"Critical Issues: {validation_results['summary']['critical_issues']}\")\n",
    "    print(f\"Warnings: {validation_results['summary']['warnings']}\")\n",
    "    print(f\"Total Issues: {validation_results['summary']['total_issues']}\")\n",
    "    \n",
    "    if recommendations:\n",
    "        print(f\"\\nRecommendations:\")\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"{i}. {rec}\")\n",
    "    \n",
    "    quality_rating = \"Excellent\" if validation_results['data_quality_score'] >= 95 else \\\n",
    "                    \"Good\" if validation_results['data_quality_score'] >= 85 else \\\n",
    "                    \"Fair\" if validation_results['data_quality_score'] >= 70 else \"Poor\"\n",
    "    \n",
    "    print(f\"\\nOverall Data Quality Rating: {quality_rating}\")\n",
    "    \n",
    "    return validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c99ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_docs = \"\"\" Helper functions available:\n",
    "- validate_email_format(series): Check email format validity using regex patterns. Returns dict with validation results.\n",
    "- validate_phone_format(series, country_code=None): Phone number validation with international support. Returns dict with validation results.\n",
    "- validate_numeric_ranges(df, column, min_val=None, max_val=None): Range validation with boundary checks. Returns dict with validation results.\n",
    "- check_data_consistency(df): Cross-column consistency checks (date logic, percentages, age-birth, geographic, duplicate IDs). Returns dict with consistency results.\n",
    "- validate_categorical_values(df, column, allowed_values): Check against allowed value lists with fuzzy matching suggestions. Returns dict with validation results.\n",
    "- generate_validation_report(df, rules_dict): Comprehensive validation report with data quality scoring. Returns detailed validation report.\n",
    "\n",
    "Examples:\n",
    "- \"Validate email addresses\" -> email_results = validate_email_format(df['email'])\n",
    "- \"Check phone numbers\" -> phone_results = validate_phone_format(df['phone'], 'US')\n",
    "- \"Validate age range\" -> age_results = validate_numeric_ranges(df, 'age', min_val=0, max_val=150)\n",
    "- \"Check data consistency\" -> consistency = check_data_consistency(df)\n",
    "- \"Validate status values\" -> status_results = validate_categorical_values(df, 'status', ['active', 'inactive'])\n",
    "- \"Generate validation report\" -> report = generate_validation_report(df, rules_dict)\n",
    "\n",
    "Rules dictionary format:\n",
    "rules = {\n",
    "    'email_columns': ['email', 'contact_email'],\n",
    "    'phone_columns': ['phone', 'mobile'],\n",
    "    'phone_country_code': 'US',\n",
    "    'range_rules': {'age': {'min': 0, 'max': 150}, 'salary': {'min': 0}},\n",
    "    'categorical_rules': {'status': ['active', 'inactive'], 'category': ['A', 'B', 'C']},\n",
    "    'required_columns': ['id', 'name', 'email']\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b02315b",
   "metadata": {},
   "source": [
    "# **MAIN FEATURE FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "881f15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(df, user_query):\n",
    "    \"\"\"\n",
    "    Main function that gets called by the main router.\n",
    "    MUST take (df, user_query) and return df\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create message chain\n",
    "    messages = []\n",
    "    messages.append(SystemMessage(content=helper_docs))\n",
    "    messages.append(SystemMessage(content=f\"\"\"\n",
    "    You are a data cleaning agent focused on data validation and quality checking.\n",
    "    \n",
    "    Dataset info: Shape: {df.shape}, Sample: {df.head(3).to_string()}\n",
    "\n",
    "    Libraries available:\n",
    "    - pd (pandas), np (numpy)\n",
    "    - math, re, datetime\n",
    "    - sklearn.preprocessing\n",
    "    - All helper functions listed above\n",
    "    \n",
    "    Rules:\n",
    "    - Return only executable Python code, no explanations, no markdown blocks\n",
    "    - Use helper functions for validation tasks - they print detailed results automatically\n",
    "    - ASSUME \"df\" IS ALREADY DEFINED\n",
    "    - For validation queries, use appropriate helper functions that print results\n",
    "    - Most validation functions return dictionaries with results - you can store these in variables if needed\n",
    "    - ALWAYS assign the result back to df only when modifying the DataFrame\n",
    "    - In order to generate a response/message to the user use print statements\n",
    "    print(\"message\")\n",
    "    - Write a detailed print message to summarise actions taken and validation results\n",
    "    \n",
    "    Common query patterns:\n",
    "    - \"Validate email addresses\" or \"Check email format\" -> validate_email_format(df['email_column'])\n",
    "    - \"Check phone numbers\" or \"Validate phone format\" -> validate_phone_format(df['phone_column'], 'US')\n",
    "    - \"Check age range\" or \"Validate ages\" -> validate_numeric_ranges(df, 'age', min_val=0, max_val=150)\n",
    "    - \"Check data consistency\" or \"Find inconsistencies\" -> check_data_consistency(df)\n",
    "    - \"Validate status values\" or \"Check categories\" -> validate_categorical_values(df, 'status', ['active', 'inactive'])\n",
    "    - \"Generate validation report\" -> create rules_dict and use generate_validation_report(df, rules_dict)\n",
    "    - \"Find data quality issues\" -> check_data_consistency(df) or generate comprehensive validation\n",
    "    \n",
    "    For comprehensive validation, create a rules dictionary like:\n",
    "    rules = {{\n",
    "        'email_columns': ['email'],\n",
    "        'phone_columns': ['phone'],\n",
    "        'range_rules': {{'age': {{'min': 0, 'max': 150}}}},\n",
    "        'categorical_rules': {{'status': ['active', 'inactive']}},\n",
    "        'required_columns': ['id', 'name']\n",
    "    }}\n",
    "    Then use: generate_validation_report(df, rules)\n",
    "    \"\"\"))\n",
    "    messages.append(HumanMessage(content=f\"User request: {user_query}\"))\n",
    "    \n",
    "    # Call LLM with message chain\n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    response = llm.invoke(messages)\n",
    "    generated_code = response.content.strip()\n",
    "    \n",
    "    # Execute code\n",
    "    try:\n",
    "        original_df = df.copy()\n",
    "        # Create local namespace with our variables\n",
    "        local_vars = {\n",
    "            'df': df.copy(),\n",
    "            'original_df': original_df,\n",
    "            'pd': pd,\n",
    "            'np': np,\n",
    "            'math': math,\n",
    "            're': re,\n",
    "            'datetime': datetime,\n",
    "            'validate_email_format': validate_email_format,\n",
    "            'validate_phone_format': validate_phone_format,\n",
    "            'validate_numeric_ranges': validate_numeric_ranges,\n",
    "            'check_data_consistency': check_data_consistency,\n",
    "            'validate_categorical_values': validate_categorical_values,\n",
    "            'generate_validation_report': generate_validation_report,\n",
    "            'print': print\n",
    "        }\n",
    "        \n",
    "        exec(generated_code, globals(), local_vars)\n",
    "        return local_vars['df']\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Generated Code:{generated_code}\")\n",
    "        return original_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30928b6",
   "metadata": {},
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataFrame created:\n",
      "Shape: (10, 10)\n",
      "\\nSample data:\n",
      "   id            name                     email            phone  age  \\\n",
      "0   1        John Doe        john.doe@email.com   (555) 123-4567   25   \n",
      "1   2      Jane Smith      jane.smith@email.com     555-987-6543   35   \n",
      "2   3     Bob Johnson               bob@invalid              123   -5   \n",
      "3   4     Alice Brown   alice.brown@company.com  +1-555-246-8135   45   \n",
      "4   5  Charlie Wilson  charlie.wilson@email.com     555.369.2580  200   \n",
      "\n",
      "     status  salary birth_date  percentage_a  percentage_b  \n",
      "0    active   50000 1998-01-15            30            70  \n",
      "1  inactive   75000 1988-05-22            40            50  \n",
      "2   pending   60000 2030-03-10            50            30  \n",
      "3    active   85000 1978-12-05            45            40  \n",
      "4  inactive  -10000 1824-07-18            35            45  \n",
      "\\nData types:\n",
      "id                       int64\n",
      "name                    object\n",
      "email                   object\n",
      "phone                   object\n",
      "age                      int64\n",
      "status                  object\n",
      "salary                   int64\n",
      "birth_date      datetime64[ns]\n",
      "percentage_a             int64\n",
      "percentage_b             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# # Create sample data with various validation issues for testing\n",
    "# test_data = {\n",
    "#     'id': [1, 2, 3, 4, 5, 5, 7, 8, 9, 10],  # Duplicate ID at index 5\n",
    "#     'name': ['John Doe', 'Jane Smith', 'Bob Johnson', 'Alice Brown', 'Charlie Wilson', \n",
    "#              'Diana Davis', 'Eve Miller', 'Frank Garcia', 'Grace Rodriguez', 'Henry Martinez'],\n",
    "#     'email': ['john.doe@email.com', 'jane.smith@email.com', 'bob@invalid', 'alice.brown@company.com',\n",
    "#               'charlie.wilson@email.com', 'diana.davis@email.com', 'eve@', 'frank.garcia@email.com',\n",
    "#               'grace.rodriguez@email.com', 'henry martinez@email.com'],  # Various email issues\n",
    "#     'phone': ['(555) 123-4567', '555-987-6543', '123', '+1-555-246-8135', '555.369.2580',\n",
    "#               '(555) 147-2583', 'abc-def-ghij', '+1-555-789-0123', '555-456-7890', '555-321-9876'],\n",
    "#     'age': [25, 35, -5, 45, 200, 30, 28, 42, 33, 29],  # Invalid ages: -5, 200\n",
    "#     'status': ['active', 'inactive', 'pending', 'active', 'inactive', \n",
    "#                'active', 'unknown', 'active', 'inactive', 'expired'],  # Invalid: pending, unknown, expired\n",
    "#     'salary': [50000, 75000, 60000, 85000, -10000, 95000, 70000, 80000, 65000, 55000],  # Invalid: -10000\n",
    "#     'birth_date': ['1998-01-15', '1988-05-22', '2030-03-10', '1978-12-05', '1824-07-18',  # Invalid dates\n",
    "#                    '1993-11-30', '1995-08-14', '1981-04-27', '1990-09-12', '1994-06-08'],\n",
    "#     'percentage_a': [30, 40, 50, 45, 35, 25, 55, 60, 40, 30],\n",
    "#     'percentage_b': [70, 50, 30, 40, 45, 75, 35, 30, 50, 60],  # Some don't sum to 100%\n",
    "# }\n",
    "\n",
    "# test_df = pd.DataFrame(test_data)\n",
    "# # Convert birth_date to datetime\n",
    "# test_df['birth_date'] = pd.to_datetime(test_df['birth_date'], errors='coerce')\n",
    "\n",
    "# print(\"Test DataFrame created:\")\n",
    "# print(f\"Shape: {test_df.shape}\")\n",
    "# print(\"\\\\nSample data:\")\n",
    "# print(test_df.head())\n",
    "# print(\"\\\\nData types:\")\n",
    "# print(test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9610f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING EMAIL VALIDATION ===\n",
      "=== EMAIL VALIDATION RESULTS ===\n",
      "Total records: 10\n",
      "Non-null records: 10\n",
      "Valid emails: 7\n",
      "Invalid emails: 3\n",
      "Null emails: 0\n",
      "Validity rate: 70.0%\n",
      "\n",
      "Sample invalid emails:\n",
      "  bob@invalid\n",
      "  eve@\n",
      "  henry martinez@email.com\n",
      "\n",
      "Common issues found:\n",
      "  Missing domain extension: 2 cases\n",
      "  Contains whitespace: 1 cases\n",
      "\\n=== TESTING PHONE VALIDATION ===\n",
      "=== PHONE VALIDATION RESULTS ===\n",
      "Country code: US\n",
      "Total records: 10\n",
      "Non-null records: 10\n",
      "Valid phones: 6\n",
      "Invalid phones: 4\n",
      "Null phones: 0\n",
      "Validity rate: 60.0%\n",
      "\n",
      "Sample invalid phones:\n",
      "  (555) 123-4567\n",
      "  123\n",
      "  (555) 147-2583\n",
      "  abc-def-ghij\n",
      "\n",
      "Common issues found:\n",
      "  Too short (< 7 digits): 1 cases\n",
      "  Contains letters: 1 cases\n",
      "\\n=== TESTING NUMERIC RANGE VALIDATION ===\n",
      "=== NUMERIC RANGE VALIDATION: age ===\n",
      "Range constraints: 0 to 150\n",
      "Total records: 10\n",
      "Non-null records: 10\n",
      "Valid values: 8\n",
      "Invalid values: 2\n",
      "Null values: 0\n",
      "Validity rate: 80.0%\n",
      "Values below minimum (0): 1\n",
      "Values above maximum (150): 1\n",
      "\n",
      "Data statistics:\n",
      "  Actual range: -5.00 to 200.00\n",
      "  Mean: 46.20\n",
      "  Std Dev: 55.71\n",
      "\n",
      "Out-of-range samples:\n",
      "  Below min (0): -5\n",
      "  Above max (150): 200\n",
      "\\n=== TESTING CATEGORICAL VALIDATION ===\n",
      "=== CATEGORICAL VALIDATION: status ===\n",
      "Total records: 10\n",
      "Non-null records: 10\n",
      "Valid values: 7\n",
      "Invalid values: 3\n",
      "Null values: 0\n",
      "Validity rate: 70.0%\n",
      "Unique values found: 5\n",
      "Allowed values: 2\n",
      "\n",
      "Invalid values found:\n",
      "  'pending': 1 occurrences\n",
      "  'unknown': 1 occurrences\n",
      "  'expired': 1 occurrences\n",
      "\n",
      "Allowed values: ['active', 'inactive']\n",
      "\\n=== TESTING DATA CONSISTENCY CHECK ===\n",
      "=== DATA CONSISTENCY CHECK ===\n",
      "DataFrame shape: (10, 10)\n",
      "❌ Percentage sum issue: 8 records with percentage sums outside 95-105%\n",
      "❌ Age-birth date mismatch: 9 records with >1 year difference\n",
      "❌ Age-birth date mismatch: 10 records with >1 year difference\n",
      "❌ Age-birth date mismatch: 10 records with >1 year difference\n",
      "❌ Duplicate IDs: 1 duplicate values in id\n",
      "\n",
      "=== CONSISTENCY SUMMARY ===\n",
      "Total consistency checks performed: 5\n",
      "Checks passed: 0\n",
      "Checks failed: 5\n",
      "Consistency rate: 0.0%\n",
      "\n",
      "Issues found:\n",
      "  • Percentage columns ['percentage_a', 'percentage_b'] do not sum to ~100%: 8 records\n",
      "  • age inconsistent with birth_date: 9 records\n",
      "  • percentage_a inconsistent with birth_date: 10 records\n",
      "  • percentage_b inconsistent with birth_date: 10 records\n",
      "  • Duplicate values in ID column id: 1 records\n"
     ]
    }
   ],
   "source": [
    "# # Test individual validation functions\n",
    "# print(\"=== TESTING EMAIL VALIDATION ===\")\n",
    "# email_results = validate_email_format(test_df['email'])\n",
    "\n",
    "# print(\"\\\\n=== TESTING PHONE VALIDATION ===\")\n",
    "# phone_results = validate_phone_format(test_df['phone'], 'US')\n",
    "\n",
    "# print(\"\\\\n=== TESTING NUMERIC RANGE VALIDATION ===\")\n",
    "# age_results = validate_numeric_ranges(test_df, 'age', min_val=0, max_val=150)\n",
    "\n",
    "# print(\"\\\\n=== TESTING CATEGORICAL VALIDATION ===\")\n",
    "# status_results = validate_categorical_values(test_df, 'status', ['active', 'inactive'])\n",
    "\n",
    "# print(\"\\\\n=== TESTING DATA CONSISTENCY CHECK ===\")\n",
    "# consistency_results = check_data_consistency(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55f9c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test comprehensive validation report\n",
    "# validation_rules = {\n",
    "#     'email_columns': ['email'],\n",
    "#     'phone_columns': ['phone'],\n",
    "#     'phone_country_code': 'US',\n",
    "#     'range_rules': {\n",
    "#         'age': {'min': 0, 'max': 150},\n",
    "#         'salary': {'min': 0}\n",
    "#     },\n",
    "#     'categorical_rules': {\n",
    "#         'status': ['active', 'inactive']\n",
    "#     },\n",
    "#     'required_columns': ['id', 'name', 'email']\n",
    "# }\n",
    "\n",
    "# print(\"\\\\n=== TESTING COMPREHENSIVE VALIDATION REPORT ===\")\n",
    "# report = generate_validation_report(test_df, validation_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tpf7qzratd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n=== TESTING MAIN VALIDATION FUNCTION ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EMAIL VALIDATION RESULTS ===\n",
      "Total records: 10\n",
      "Non-null records: 10\n",
      "Valid emails: 7\n",
      "Invalid emails: 3\n",
      "Null emails: 0\n",
      "Validity rate: 70.0%\n",
      "\n",
      "Sample invalid emails:\n",
      "  bob@invalid\n",
      "  eve@\n",
      "  henry martinez@email.com\n",
      "\n",
      "Common issues found:\n",
      "  Missing domain extension: 2 cases\n",
      "  Contains whitespace: 1 cases\n",
      "\\n==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPREHENSIVE VALIDATION REPORT ===\n",
      "DataFrame shape: (10, 10)\n",
      "Validation started at: 2025-09-13 17:14:01\n",
      "\n",
      "--- Required Columns Check ---\n",
      "✅ All required columns present\n",
      "\n",
      "--- Email Validation ---\n",
      "=== EMAIL VALIDATION RESULTS ===\n",
      "Total records: 10\n",
      "Non-null records: 10\n",
      "Valid emails: 7\n",
      "Invalid emails: 3\n",
      "Null emails: 0\n",
      "Validity rate: 70.0%\n",
      "\n",
      "Sample invalid emails:\n",
      "  bob@invalid\n",
      "  eve@\n",
      "  henry martinez@email.com\n",
      "\n",
      "Common issues found:\n",
      "  Missing domain extension: 2 cases\n",
      "  Contains whitespace: 1 cases\n",
      "\n",
      "--- Phone Validation ---\n",
      "=== PHONE VALIDATION RESULTS ===\n",
      "Country code: International\n",
      "Total records: 10\n",
      "Non-null records: 10\n",
      "Valid phones: 8\n",
      "Invalid phones: 2\n",
      "Null phones: 0\n",
      "Validity rate: 80.0%\n",
      "\n",
      "Sample invalid phones:\n",
      "  123\n",
      "  abc-def-ghij\n",
      "\n",
      "Common issues found:\n",
      "  Too short (< 7 digits): 1 cases\n",
      "  Contains letters: 1 cases\n",
      "  Missing country code (+): 8 cases\n",
      "\n",
      "--- Numeric Range Validation ---\n",
      "=== NUMERIC RANGE VALIDATION: age ===\n",
      "Range constraints: 0 to 150\n",
      "Total records: 10\n",
      "Non-null records: 10\n",
      "Valid values: 8\n",
      "Invalid values: 2\n",
      "Null values: 0\n",
      "Validity rate: 80.0%\n",
      "Values below minimum (0): 1\n",
      "Values above maximum (150): 1\n",
      "\n",
      "Data statistics:\n",
      "  Actual range: -5.00 to 200.00\n",
      "  Mean: 46.20\n",
      "  Std Dev: 55.71\n",
      "\n",
      "Out-of-range samples:\n",
      "  Below min (0): -5\n",
      "  Above max (150): 200\n",
      "\n",
      "--- Categorical Validation ---\n",
      "=== CATEGORICAL VALIDATION: status ===\n",
      "Total records: 10\n",
      "Non-null records: 10\n",
      "Valid values: 7\n",
      "Invalid values: 3\n",
      "Null values: 0\n",
      "Validity rate: 70.0%\n",
      "Unique values found: 5\n",
      "Allowed values: 2\n",
      "\n",
      "Invalid values found:\n",
      "  'pending': 1 occurrences\n",
      "  'unknown': 1 occurrences\n",
      "  'expired': 1 occurrences\n",
      "\n",
      "Allowed values: ['active', 'inactive']\n",
      "\n",
      "--- Data Consistency Check ---\n",
      "=== DATA CONSISTENCY CHECK ===\n",
      "DataFrame shape: (10, 10)\n",
      "❌ Percentage sum issue: 8 records with percentage sums outside 95-105%\n",
      "❌ Age-birth date mismatch: 9 records with >1 year difference\n",
      "❌ Age-birth date mismatch: 10 records with >1 year difference\n",
      "❌ Age-birth date mismatch: 10 records with >1 year difference\n",
      "❌ Duplicate IDs: 1 duplicate values in id\n",
      "\n",
      "=== CONSISTENCY SUMMARY ===\n",
      "Total consistency checks performed: 5\n",
      "Checks passed: 0\n",
      "Checks failed: 5\n",
      "Consistency rate: 0.0%\n",
      "\n",
      "Issues found:\n",
      "  • Percentage columns ['percentage_a', 'percentage_b'] do not sum to ~100%: 8 records\n",
      "  • age inconsistent with birth_date: 9 records\n",
      "  • percentage_a inconsistent with birth_date: 10 records\n",
      "  • percentage_b inconsistent with birth_date: 10 records\n",
      "  • Duplicate values in ID column id: 1 records\n",
      "\n",
      "=== VALIDATION SUMMARY ===\n",
      "Data Quality Score: 75.0%\n",
      "Critical Issues: 2\n",
      "Warnings: 9\n",
      "Total Issues: 11\n",
      "\n",
      "Recommendations:\n",
      "1. Data quality score is below 80%. Consider comprehensive data cleaning.\n",
      "2. Address 2 critical data quality issues.\n",
      "3. Multiple validation warnings detected. Review data entry processes.\n",
      "\n",
      "Overall Data Quality Rating: Fair\n",
      "Comprehensive validation report generated successfully.\n",
      "\\n==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA CONSISTENCY CHECK ===\n",
      "DataFrame shape: (10, 10)\n",
      "❌ Percentage sum issue: 8 records with percentage sums outside 95-105%\n",
      "❌ Age-birth date mismatch: 9 records with >1 year difference\n",
      "❌ Age-birth date mismatch: 10 records with >1 year difference\n",
      "❌ Age-birth date mismatch: 10 records with >1 year difference\n",
      "❌ Duplicate IDs: 1 duplicate values in id\n",
      "\n",
      "=== CONSISTENCY SUMMARY ===\n",
      "Total consistency checks performed: 5\n",
      "Checks passed: 0\n",
      "Checks failed: 5\n",
      "Consistency rate: 0.0%\n",
      "\n",
      "Issues found:\n",
      "  • Percentage columns ['percentage_a', 'percentage_b'] do not sum to ~100%: 8 records\n",
      "  • age inconsistent with birth_date: 9 records\n",
      "  • percentage_a inconsistent with birth_date: 10 records\n",
      "  • percentage_b inconsistent with birth_date: 10 records\n",
      "  • Duplicate values in ID column id: 1 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "# # Test the main validation function with various queries\n",
    "# print(\"\\\\n=== TESTING MAIN VALIDATION FUNCTION ===\")\n",
    "\n",
    "# # Test query 1: Validate email addresses\n",
    "# query1 = \"Validate email addresses in the dataset\"\n",
    "# result1 = validation(test_df, query1)\n",
    "\n",
    "# print(\"\\\\n\" + \"=\"*50)\n",
    "\n",
    "# # Test query 2: Generate validation report\n",
    "# query2 = \"Generate a comprehensive validation report for data quality\"\n",
    "# result2 = validation(test_df, query2)\n",
    "\n",
    "# print(\"\\\\n\" + \"=\"*50)\n",
    "\n",
    "# # Test query 3: Check data consistency\n",
    "# query3 = \"Check for data consistency issues\"\n",
    "# result3 = validation(test_df, query3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
